# -*- coding: utf-8 -*-
"""breast-cancer-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCOq0-e4APTC4WTG9laOiNvjGJ6f-9G9

import libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os

import warnings
warnings.filterwarnings('ignore')
import kagglehub

"""### Data Preparation

download dataset di kaggle
"""

# download data dari kaggle
path = kagglehub.dataset_download("yasserh/breast-cancer-dataset")

print("Path to dataset files:", path)

"""load data csv"""

df=pd.read_csv("C:/Users/rizki/.cache/kagglehub/datasets/yasserh/breast-cancer-dataset/versions/1/breast-cancer.csv")
df.columns

"""cek 5 data teratas"""

df.head()

"""### Data Cleaning

cek duplikat
"""

df.duplicated().sum()

"""cek missing value"""

#cek null pada dataframe
df.isnull().sum()

"""cek ukuran dataframe"""

df.shape

"""cek jumlah data keseluruhan"""

df.size

"""berdasarkan hasil cek data tidak memiliki missing value dan duplicate value

### EDA

cek unique value
"""

# melihat nilai unik setiap variabel
df.nunique()

"""drop id karna tidak memiliki korelasi apapun"""

# menghilangkan id dari df
df=df.drop('id',axis=1)

"""merangkum Statistik deskriptif pada dataframe"""

df.describe()

"""### Univariate Analysis

visualisasi fitur kategorikal
"""

# membuat visualisasi bar chart
sns.countplot(x='diagnosis',data=df,palette='Blues_d')

"""berdasarkan gambar diatas bahwa nilai benign lebih banyak dari malignant.

### Multivariate Analysis

visualisasi fitur numerikal
"""

# menghilangkan  diagnosis dari df_corr
df_corr= df.drop('diagnosis',axis=1)

# memvisualisasikan korelasi antar variabel
corr=plt.figure(figsize=(30,20))
sns.heatmap(df_corr.corr(),annot=True,cmap='Blues')

"""berdasarkan gambar diatas bahwa Fitur radius, perimeter dan area memiliki korelasi sangat kuat satu sama lain, yang menunjukkan bahwa ketika satu nilai meningkat, yang lain juga cenderung meningkat."""

# drop data agar hanya satu bagian bagian field
df_mean = df.drop(columns=[col for col in df.columns if '_se' in col or '_worst' in col])
df_se = df.drop(columns=[col for col in df.columns if '_mean' in col or '_worst' in col])
df_worst = df.drop(columns=[col for col in df.columns if '_se' in col or '_mean' in col])

"""visualisasi pairplot pada field mean, standart error dan worst"""

# membuat visualisasi pairplot untuk data df_mean
sns.pairplot(df_mean, hue='diagnosis', palette='Blues_d')

"""berdasarkan gambar diatas bahwa beberapa korelasi positif terlihat kuat antara fitur seperti radius_mean, perimeter_mean, dan area_mean, terutama membedakan dua kelas diagnosis."""

# membuat visualisasi pairplot untuk data df_se
sns.pairplot(df_se, hue='diagnosis', palette='Blues_d')

"""berdasarkan gambar diatas bahwa sebagian besar fitur tidak memiliki korelasi yang kuat satu sama lain, kecuali beberapa fitur seperti radius_se, perimeter_se, dan area_se, yang menunjukkan korelasi lumayan kuat. Fitur-fitur ini masih cukup baik dalam memisahkan dua kelas diagnosis."""

# membuat visualisasi pairplot untuk data df_worst
sns.pairplot(df_worst, hue='diagnosis', palette='Blues_d')

"""berdasarkan gambar diatas bahwa ada beberapa korelasi yang sangat kuat antara fitur seperti radius_worst, perimeter_worst, dan area_worst.

mendeteksi outliers dengan visualisasi menggunakan boxplot pada field mean, standart error dan worst
"""

# membuat visualisasi boxplot menggunakan df_mean
n_cols = 3
n_rows = (len(df_mean.columns) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))
axes = axes.flatten()


for i, col in enumerate(df_mean.columns):
    sns.boxplot(x='diagnosis', y=col, data=df_mean, ax=axes[i])
    axes[i].set_title(f'Boxplot of {col} by Diagnosis')


for j in range(i + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""berdasarkan gambar diatas bahwa terdapat banyak nilai outliers pada field mean."""

# membuat visualisasi boxplot menggunakan df_se
n_cols = 3
n_rows = (len(df_se.columns) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))
axes = axes.flatten()


for i, col in enumerate(df_se.columns):
    sns.boxplot(x='diagnosis', y=col, data=df_se, ax=axes[i])
    axes[i].set_title(f'Boxplot of {col} by Diagnosis')


for j in range(i + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""berdasarkan gambar diatas bahwa terdapat banyak nilai outliers pada field standart error."""

# membuat visualisasi boxplot menggunakan df_worst
n_cols = 3
n_rows = (len(df_worst.columns) + n_cols - 1) // n_cols

fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))
axes = axes.flatten()


for i, col in enumerate(df_worst.columns):
    sns.boxplot(x='diagnosis', y=col, data=df_worst, ax=axes[i])
    axes[i].set_title(f'Boxplot of {col} by Diagnosis')


for j in range(i + 1, n_rows * n_cols):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""berdasarkan gambar diatas bahwa terdapat banyak nilai outliers pada field worst.

### Data Preprocessing

label encoder fitur kategorikal
"""

# melakukan labelencoder variabel diagnosis
from sklearn.preprocessing import LabelEncoder
l=LabelEncoder()
df['diagnosis']=l.fit_transform(df.diagnosis)
df.head()

"""handling outliers dengan cara menghapus data yang tidak kurang dari batas bawah dan tidak lebih dari batas atas"""

# menghilangkan data outliers
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

df_clean = df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]

"""split data menjadi data train dan test"""

# membagi data menjadi train dan test menjadi 70:30
from sklearn.model_selection import train_test_split
x=df.drop('diagnosis',axis=1)
y=df['diagnosis']
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=42)

"""standart scaler data train dan test"""

# melakukan standard scaler
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
xtrain = scaler.fit_transform(xtrain)
xtest = scaler.transform(xtest)

"""### Modeling

#### model development random forest

membuat model random forest menggunakan 100 n_estimators dan dibatasi dengan kedalaman maksimum 3 untuk menjaga keseimbangan antara bias dan variansi.
"""

from sklearn.ensemble import RandomForestClassifier
model_RandomForest = RandomForestClassifier(n_estimators=100, max_depth=3)
model_RandomForest.fit(xtrain, ytrain)
y_pred_RandomForest = model_RandomForest.predict(xtest)

"""#### model development adapative boosting

membuat model decision tree sebagai weak learners dengan kedalaman maksimum(max_depth) sebesar 3, yang berarti pohon keputusan dibatasi hingga tiga tingkat untuk mencegah overfitting.
"""

from sklearn.tree import DecisionTreeClassifier

model_DecisionTree = DecisionTreeClassifier(max_depth=3)
model_DecisionTree.fit(xtrain, ytrain)
y_pred_DecisionTree = model_DecisionTree.predict(xtest)

"""membuat model adaboost dengan estimator berupa model Decision Tree yang memiliki kedalaman maksimum 3 dan jumlah estimators sebanyak 1000."""

from sklearn.ensemble import AdaBoostClassifier

model_AdaBoost = AdaBoostClassifier(estimator=model_DecisionTree,n_estimators=1000)
model_AdaBoost.fit(xtrain, ytrain)
y_pred = model_AdaBoost.predict(xtest)

"""### Evaluation

hasil  classification report model decision tree
"""

from sklearn.metrics import classification_report, confusion_matrix
# evaluasi hasil train model decision tree
print("Decision Tree")
print(classification_report(ytest, y_pred_DecisionTree))
print(confusion_matrix(ytest, y_pred_DecisionTree))

"""hasil  classification report model adaptive boosting"""

# evaluasi hasil train model adaptive boosting
print("Decision Tree + Adaboost")
print(classification_report(ytest, y_pred))
print(confusion_matrix(ytest, y_pred))

"""hasil  classification report model random forest"""

# evaluasi hasil train model random forest
print("Random Forest")
print(classification_report(ytest, y_pred_RandomForest))
print(confusion_matrix(ytest, y_pred_RandomForest))

""" Berdasarkan hasil classification report AdaBoost lebih unggul dalam hal menangani kesalahan prediksi dan akurasi pada dataset daripada Random Forest dengan metrik presisi 1%, akurasi, recall dan F1 score lebih tinggi 2%."""